{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependences\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mr-ma\\Documents\\GitHub\\web-scraping-challenge\\Missions_to_Mars\\mission_to_mars.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mr-ma/Documents/GitHub/web-scraping-challenge/Missions_to_Mars/mission_to_mars.ipynb#ch0000002?line=11'>12</a>\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mr-ma/Documents/GitHub/web-scraping-challenge/Missions_to_Mars/mission_to_mars.ipynb#ch0000002?line=14'>15</a>\u001b[0m parent_class \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mselect_one(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlist_text\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mr-ma/Documents/GitHub/web-scraping-challenge/Missions_to_Mars/mission_to_mars.ipynb#ch0000002?line=17'>18</a>\u001b[0m news_title \u001b[39m=\u001b[39m parent_class\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m'\u001b[39;49m, class_\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcontent_title\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mget_text()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mr-ma/Documents/GitHub/web-scraping-challenge/Missions_to_Mars/mission_to_mars.ipynb#ch0000002?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(news_title)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mr-ma/Documents/GitHub/web-scraping-challenge/Missions_to_Mars/mission_to_mars.ipynb#ch0000002?line=20'>21</a>\u001b[0m news \u001b[39m=\u001b[39m parent_class\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39marticle_teaser_body\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_text()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# splinter method\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# ------constaint errors throught the notebook without the above method added each time scraping happends on a new page-----\n",
    "\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "parent_class = soup.select_one('div', class_='list_text')\n",
    "\n",
    "\n",
    "news_title = parent_class.find('div', class_='content_title').get_text()\n",
    "print(news_title)\n",
    "\n",
    "news = parent_class.find('div', class_='article_teaser_body').get_text()\n",
    "print(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JPL Mars Space Images - Featured Image\n",
    "Visit the url for the Featured Space Image page here (https://spaceimages-mars.com/)\n",
    "\n",
    "Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "\n",
    "Make sure to find the image url to the full size .jpg image.\n",
    "Make sure to save a complete url string for this image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://spaceimages-mars.com/image/featured/mars3.jpg\n"
     ]
    }
   ],
   "source": [
    "# splinter method\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# ------constaint errors throught the notebook without the above method added each time scraping happends on a new page-----\n",
    "\n",
    "mars_url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(mars_url)\n",
    "\n",
    "html_mars = browser.html\n",
    "\n",
    "soup = BeautifulSoup(html_mars, 'html.parser')\n",
    "\n",
    "featured_url = soup.find(\"img\", class_=\"headerimage fade-in\")[\"src\"]\n",
    "featured_image_url = f'https://spaceimages-mars.com/{featured_url}'\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_url= 'https://spaceimages-mars.com/image/featured/mars1.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Facts\n",
    "\n",
    "\n",
    "Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "\n",
    "Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://galaxyfacts-mars.com/'\n",
    "tables = pd.read_html(url)\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The task asked for the planet so I asssumed mars. \n",
    "\n",
    "df = tables[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.columns =[\"Comparison\",\"Mars\", \"Earth\"]\n",
    "cleaned_df = df.iloc[1:, :]\n",
    "html_table = cleaned_df.to_html()\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# splinter method\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "\n",
    "url_hem = 'https://marshemispheres.com/'\n",
    "browser.visit(url_hem)\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results = soup.find_all('div', class_='item')\n",
    "# image_url = soup.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "# print(url_hem + image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splinter method\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# ---------------------------------------------SEE test notebook where the code executed correctly, still troubleshooting why the code is \n",
    "# not working in this notebook. Likely my extenstion is not reading the code correctly after a point---------------------------------------------------- \n",
    "\n",
    "# list to hold the images and titles.\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Code to retrieve the image urls and titles for each hemisphere.\n",
    "\n",
    "# First, we need to get a get a list of all of the hemispheres\n",
    "links = browser.find_by_css('a.product-item img')\n",
    "\n",
    "# Next, loop through those links, click the link, find the sample anchor, and return the href we want\n",
    "for i in range(len(links)):\n",
    "    hemisphere = {}\n",
    "    \n",
    "    # We have to find the elements on each loop to avoid a stale element exception\n",
    "    browser.find_by_css('a.product-item img')[i].click()\n",
    "    \n",
    "    #  Sample image anchor tag and extract the href\n",
    "    sample_elem = browser.links.find_by_text('Sample').first\n",
    "    hemisphere['img_url'] = sample_elem['href']\n",
    "    \n",
    "    # Get Hemisphere title\n",
    "    hemisphere['title'] = browser.find_by_css('h2.title').text\n",
    "    \n",
    "    # Append hemisphere object to list\n",
    "    hemisphere_image_urls.append(hemisphere)\n",
    "    \n",
    "    # Finally, we navigate backwards\n",
    "    browser.back()\n",
    "hemisphere_image_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('bootcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abb041905d78b0e8d42a8ca89e8df410324f3397d57804e78a833def6a13175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
